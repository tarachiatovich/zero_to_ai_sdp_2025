{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73142fd6-52d5-4840-a66f-42af4f94817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d22aa5b6-482e-4244-915a-76d0d56384f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              name     role         type  \\\n",
      "0                                   Marital Status  Feature      Integer   \n",
      "1                                 Application mode  Feature      Integer   \n",
      "2                                Application order  Feature      Integer   \n",
      "3                                           Course  Feature      Integer   \n",
      "4                       Daytime/evening attendance  Feature      Integer   \n",
      "5                           Previous qualification  Feature      Integer   \n",
      "6                   Previous qualification (grade)  Feature   Continuous   \n",
      "7                                      Nacionality  Feature      Integer   \n",
      "8                           Mother's qualification  Feature      Integer   \n",
      "9                           Father's qualification  Feature      Integer   \n",
      "10                             Mother's occupation  Feature      Integer   \n",
      "11                             Father's occupation  Feature      Integer   \n",
      "12                                 Admission grade  Feature   Continuous   \n",
      "13                                       Displaced  Feature      Integer   \n",
      "14                       Educational special needs  Feature      Integer   \n",
      "15                                          Debtor  Feature      Integer   \n",
      "16                         Tuition fees up to date  Feature      Integer   \n",
      "17                                          Gender  Feature      Integer   \n",
      "18                              Scholarship holder  Feature      Integer   \n",
      "19                               Age at enrollment  Feature      Integer   \n",
      "20                                   International  Feature      Integer   \n",
      "21             Curricular units 1st sem (credited)  Feature      Integer   \n",
      "22             Curricular units 1st sem (enrolled)  Feature      Integer   \n",
      "23          Curricular units 1st sem (evaluations)  Feature      Integer   \n",
      "24             Curricular units 1st sem (approved)  Feature      Integer   \n",
      "25                Curricular units 1st sem (grade)  Feature      Integer   \n",
      "26  Curricular units 1st sem (without evaluations)  Feature      Integer   \n",
      "27             Curricular units 2nd sem (credited)  Feature      Integer   \n",
      "28             Curricular units 2nd sem (enrolled)  Feature      Integer   \n",
      "29          Curricular units 2nd sem (evaluations)  Feature      Integer   \n",
      "30             Curricular units 2nd sem (approved)  Feature      Integer   \n",
      "31                Curricular units 2nd sem (grade)  Feature      Integer   \n",
      "32  Curricular units 2nd sem (without evaluations)  Feature      Integer   \n",
      "33                               Unemployment rate  Feature   Continuous   \n",
      "34                                  Inflation rate  Feature   Continuous   \n",
      "35                                             GDP  Feature   Continuous   \n",
      "36                                          Target   Target  Categorical   \n",
      "\n",
      "        demographic                                        description units  \\\n",
      "0    Marital Status  1 – single 2 – married 3 – widower 4 – divorce...  None   \n",
      "1              None  1 - 1st phase - general contingent 2 - Ordinan...  None   \n",
      "2              None  Application order (between 0 - first choice; a...  None   \n",
      "3              None  33 - Biofuel Production Technologies 171 - Ani...  None   \n",
      "4              None                            1 – daytime 0 - evening  None   \n",
      "5   Education Level  1 - Secondary education 2 - Higher education -...  None   \n",
      "6              None  Grade of previous qualification (between 0 and...  None   \n",
      "7       Nationality  1 - Portuguese; 2 - German; 6 - Spanish; 11 - ...  None   \n",
      "8   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n",
      "9   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n",
      "10       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n",
      "11       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n",
      "12             None                Admission grade (between 0 and 200)  None   \n",
      "13             None                                     1 – yes 0 – no  None   \n",
      "14             None                                     1 – yes 0 – no  None   \n",
      "15             None                                     1 – yes 0 – no  None   \n",
      "16             None                                     1 – yes 0 – no  None   \n",
      "17           Gender                                1 – male 0 – female  None   \n",
      "18             None                                     1 – yes 0 – no  None   \n",
      "19              Age                       Age of studend at enrollment  None   \n",
      "20             None                                     1 – yes 0 – no  None   \n",
      "21             None  Number of curricular units credited in the 1st...  None   \n",
      "22             None  Number of curricular units enrolled in the 1st...  None   \n",
      "23             None  Number of evaluations to curricular units in t...  None   \n",
      "24             None  Number of curricular units approved in the 1st...  None   \n",
      "25             None  Grade average in the 1st semester (between 0 a...  None   \n",
      "26             None  Number of curricular units without evalutions ...  None   \n",
      "27             None  Number of curricular units credited in the 2nd...  None   \n",
      "28             None  Number of curricular units enrolled in the 2nd...  None   \n",
      "29             None  Number of evaluations to curricular units in t...  None   \n",
      "30             None  Number of curricular units approved in the 2nd...  None   \n",
      "31             None  Grade average in the 2nd semester (between 0 a...  None   \n",
      "32             None  Number of curricular units without evalutions ...  None   \n",
      "33             None                              Unemployment rate (%)  None   \n",
      "34             None                                 Inflation rate (%)  None   \n",
      "35             None                                                GDP  None   \n",
      "36             None  Target. The problem is formulated as a three c...  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n",
      "32             no  \n",
      "33             no  \n",
      "34             no  \n",
      "35             no  \n",
      "36             no  \n"
     ]
    }
   ],
   "source": [
    "# Dataset for student outcomes\n",
    "\n",
    "# Fetch dataset \n",
    "predict_students_dropout_and_academic_success = fetch_ucirepo(id=697) \n",
    "  \n",
    "# Data (as pandas dataframes) \n",
    "X = predict_students_dropout_and_academic_success.data.features \n",
    "y = predict_students_dropout_and_academic_success.data.targets \n",
    "  \n",
    "# Metadata; commenting out because it's a lot!\n",
    "# This code calling up .metadata is specific to this dataframe,\n",
    "# would not work in most pandas dataframes\n",
    "# print(predict_students_dropout_and_academic_success.metadata) \n",
    "  \n",
    "# Variable information\n",
    "# NOTE: This code works with this dataframe, but typically when\n",
    "# working in Pandas, one would pull up information on the \n",
    "# columns/variables using data_frame_name.info()\n",
    "print(predict_students_dropout_and_academic_success.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a8eeb00-7b69-451a-968c-e8bd91533677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have 3 categories, but for this demonstration, want just 2\n",
    "# Recoding Target into 2 labeled and 2 numeric categories\n",
    "# For numeric categories, 1 = 'Late grad or drop-out'\n",
    "y_recode = y.copy()\n",
    "y_recode['TargetLabel'] = np.where(y_recode['Target'] == 'Graduate', 'On-time grad', 'Late grad or drop-out')\n",
    "y_recode['TargetNumeric'] = np.where(y_recode['Target'] == 'Graduate', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab2c5ac6-e9a7-4b54-8213-acd753ae1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside 20% of the data as final testing dataset\n",
    "X_modeling, X_test, y_modeling, y_test = train_test_split(\n",
    "    X, y_recode['TargetNumeric'], test_size=0.20, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c149d07b-df92-4f92-a2cd-c9e1188d3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation data\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "    X_modeling, y_modeling, test_size=0.20, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95ac5864-ad5b-4555-a537-0bcf5529f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Forest f1 score:  0.847887323943662\n",
      "Rand Forest classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85       372\n",
      "           1       0.80      0.90      0.85       336\n",
      "\n",
      "    accuracy                           0.85       708\n",
      "   macro avg       0.85      0.85      0.85       708\n",
      "weighted avg       0.85      0.85      0.85       708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit a random forest classifier\n",
    "rand_for = RandomForestClassifier(random_state=55)\n",
    "rand_for.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "rand_for_preds = rand_for.predict(X_validate)\n",
    "\n",
    "# Print f1 score, classification report\n",
    "print('Rand Forest f1 score: ', f1_score(rand_for_preds, y_validate))\n",
    "print('Rand Forest classification_report: \\n', classification_report(rand_for_preds, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "43cdd605-055e-480b-b9db-c992c043c1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradBoostClassifier f1 score:  0.847124824684432\n",
      "GradBoostClassifier classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84       369\n",
      "           1       0.81      0.89      0.85       339\n",
      "\n",
      "    accuracy                           0.85       708\n",
      "   macro avg       0.85      0.85      0.85       708\n",
      "weighted avg       0.85      0.85      0.85       708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit a gradient boosting classifier\n",
    "grad_boost = GradientBoostingClassifier(random_state=55)\n",
    "grad_boost.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "grad_boost_preds = grad_boost.predict(X_validate)\n",
    "\n",
    "# Print f1 score, classification report\n",
    "print('Grad boost f1 score: ', f1_score(grad_boost_preds, y_validate))\n",
    "print('Grad boost classification report: \\n', classification_report(grad_boost_preds, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6dee874a-6161-4d71-95ea-9ac23308ac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost f1 score:  0.844632768361582\n",
      "XGBoost classsification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.84       374\n",
      "           1       0.80      0.90      0.84       334\n",
      "\n",
      "    accuracy                           0.84       708\n",
      "   macro avg       0.85      0.85      0.84       708\n",
      "weighted avg       0.85      0.84      0.84       708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: May exclude this part\n",
    "# Source: https://www.datacamp.com/tutorial/xgboost-in-python\n",
    "# Train a model using the scikit-learn API\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    objective='binary:logistic',\n",
    "    tree_method='hist',\n",
    "    eta=0.1,\n",
    "    max_depth=3,\n",
    "    enable_categorical=True,\n",
    "    random_state=55\n",
    ")\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Convert the model to a native API model\n",
    "model = xgb_classifier.get_booster()\n",
    "\n",
    "# Get predictions\n",
    "xgb_preds = xgb_classifier.predict(X_validate)\n",
    "\n",
    "# Print f1 score, classification report\n",
    "print('XGBoost f1 score: ', f1_score(xgb_preds, y_validate))\n",
    "print('XGBoost classsification report: \\n', classification_report(xgb_preds, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e6dbf55-5957-4b84-9131-58b3f30db194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best Model Accuracy:  0.849083215796897\n",
      "Best Model Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       334\n",
      "           1       0.90      0.80      0.85       374\n",
      "\n",
      "    accuracy                           0.85       708\n",
      "   macro avg       0.85      0.85      0.85       708\n",
      "weighted avg       0.85      0.85      0.85       708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "# You can go all out hyperparameter tuning and tune for everything.\n",
    "# For the sake of demonstrating hyperparameter tuning without making\n",
    "# you wait too long for the code to run, below I just select a few\n",
    "# hyperparameters with a couple of values to show how to set it up.\n",
    "# I am using GridSearch in scikit learn, which tries out all combinations\n",
    "# of hyperparameters and selects the best combination according to the\n",
    "# selected metric you want to optimize for. A \"quicker\" version of GridSearch\n",
    "# is RandomizedSearchCV, which randomly selects from among combinations to\n",
    "# do a good but not exhaustive job of testing out combinations with greater\n",
    "# speed. An even \"smarter\" way to hyperparameter tune is to use a tool like\n",
    "# Optuna, which searches for hyperparameter values that do a good job with the\n",
    "# metric you are optimizing for and then tries out many more values close to\n",
    "# those values to more efficiently find the best combination of values...but\n",
    "# Optuna is beyond the scope for these worked examples!\n",
    "\n",
    "# Source for code example: https://www.geeksforgeeks.org/how-to-tune-hyperparameters-in-gradient-boosting-algorithm/\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.005, 0.01, 0.1, 0.2],\n",
    "    'max_depth': [2, 3, 4],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_grad_boost = GridSearchCV(estimator=grad_boost, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data using GridSearchCV\n",
    "grid_search_grad_boost.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best model\n",
    "best_params_grad_boost = grid_search_grad_boost.best_params_\n",
    "best_model_grad_boost = grid_search_grad_boost.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_grad_boost = best_model_grad_boost.predict(X_validate)\n",
    "\n",
    "# Evaluate the best model\n",
    "f1_best_grad_boost = f1_score(y_validate, y_pred_best)\n",
    "class_report_best_grad_boost = classification_report(y_validate, y_pred_best)\n",
    "\n",
    "# Print the results\n",
    "print(\"Grad boost best parameters: \", best_params)\n",
    "print(f\"Grad boost best model f1 score:  {f1_best_grad_boost}\")\n",
    "print(f\"Grad boost best model classification report: \\n{class_report_best_grad_boost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647b64c-2094-424a-93b5-5ad179e3c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for random-forest\n",
    "# Source for example code: https://www.geeksforgeeks.org/random-forest-hyperparameter-tuning-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zero_to_ai]",
   "language": "python",
   "name": "conda-env-zero_to_ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
